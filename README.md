# ğŸ¤– Multi-Source RAG Chatbot

An intelligent RAG (Retrieval-Augmented Generation) chatbot system that integrates multiple data sources with automatic routing capabilities.

## ğŸŒŸ Key Features

### ğŸ¯ Intelligent Multi-Source Routing
- **Automatic Database Selection**: Routes queries to the appropriate data source based on content analysis
- **Dual Routing Strategy**:
  - Fast keyword-based routing for explicit queries
  - Vector similarity comparison for ambiguous questions
- **Context-Aware**: Maintains conversation context for follow-up questions

### ğŸ’¬ Advanced Conversation Management
- **Multi-turn Dialogue**: Remembers conversation history for contextual responses
- **Session Management**: Per-user conversation tracking and history
- **Vector-based History Search**: Retrieves relevant past conversations to improve answers

### ğŸ“Š Data Source Integration
- **Project Management Data**: Integrates with issue tracking systems
- **Research Data**: Supports structured research data with statistical analysis
- **Extensible Architecture**: Easy to add new data sources

### ğŸ“ˆ Statistical Analysis & Visualization
- **Automated Statistics**: Python-based calculation for numerical queries
- **Chart Generation**: Automatic visualization using Gemini Code Execution
- **Multi-field Filtering**: Complex query support with multiple conditions

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   User Query    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Intelligent Router                  â”‚
â”‚  (Keyword + Vector Similarity)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
    â”‚         â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”  â”Œâ”€â”€â–¼â”€â”€â”€â”
â”‚ DB 1 â”‚  â”‚ DB 2 â”‚  ... (Extensible)
â””â”€â”€â”€â”¬â”€â”€â”˜  â””â”€â”€â”¬â”€â”€â”€â”˜
    â”‚         â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Gemini LLM      â”‚
â”‚  (Answer Gen)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Response       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ› ï¸ Tech Stack

- **Backend**: Flask (Python 3.11)
- **Vector Database**: ChromaDB
- **LLM**: Google Gemini 2.5 Pro
- **Embedding**: Gemini Embedding 001
- **Server**: Gunicorn
- **Containerization**: Docker & Docker Compose
- **Orchestration**: Kubernetes (Deployment ready)

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ chatbot/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ app.py                  # Flask application & routing logic
â”‚   â”‚   â”œâ”€â”€ rag_engine.py          # Core RAG engine
â”‚   â”‚   â”œâ”€â”€ prompts.py             # Prompt templates
â”‚   â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”‚   â”œâ”€â”€ constants.py       # Configuration constants
â”‚   â”‚   â”‚   â”œâ”€â”€ patterns.py        # Regex patterns for routing
â”‚   â”‚   â”‚   â””â”€â”€ gunicorn_config.py # Gunicorn settings
â”‚   â”‚   â””â”€â”€ utils/
â”‚   â”‚       â”œâ”€â”€ rag_utils.py           # RAG helper functions
â”‚   â”‚       â”œâ”€â”€ rag_engine_helpers.py  # Query processing helpers
â”‚   â”‚       â””â”€â”€ crf_statistics.py      # Statistical analysis module
â”‚   â”œâ”€â”€ templates/
â”‚   â”‚   â””â”€â”€ chat.html              # Web UI
â”‚   â”œâ”€â”€ Dockerfile                 # Docker image definition
â”‚   â””â”€â”€ requirement.txt           # Python dependencies
â”œâ”€â”€ docker-compose.yml            # Docker Compose configuration
â””â”€â”€ README.md                     # This file
```

## ğŸš€ Quick Start

### Prerequisites

- Docker & Docker Compose
- Google Gemini API Key ([Get one here](https://makersuite.google.com/app/apikey))
- Vector database (ChromaDB) with your data

### Installation

1. **Clone the repository**
\`\`\`bash
git clone <repository-url>
cd rag-chatbot
\`\`\`

2. **Set up environment variables**
\`\`\`bash
cp .env.example .env
# Edit .env and add your configurations
\`\`\`

3. **Prepare your vector database**
\`\`\`bash
# Place your ChromaDB data in ./vectordb/
mkdir -p vectordb/chroma_db_v0.2.0
# Copy your ChromaDB files here
\`\`\`

4. **Run with Docker Compose**
\`\`\`bash
docker-compose up -d
\`\`\`

5. **Access the chatbot**
\`\`\`
http://localhost:<PORT>
\`\`\`

### Local Development

\`\`\`bash
cd chatbot

# Install dependencies
pip install -r requirement.txt

# Set environment variables
export GEMINI_API_KEY=your_api_key_here
export VECTORDB_PATH=/path/to/vectordb
export COLLECTION_NAME=your_collection_name

# Run the application
python src/app.py

# Or with Gunicorn
gunicorn --config src/config/gunicorn_config.py src.app:app
\`\`\`

## ğŸ“¡ API Endpoints

### \`POST /chat\`
Main chatbot endpoint with automatic routing

**Request:**
\`\`\`json
{
  "question": "What is the latest model performance?",
  "user_name": "user123",
  "top_k": 5
}
\`\`\`

**Response:**
\`\`\`json
{
  "answer": "The latest model achieved 95% accuracy...",
  "sources": [
    {
      "issue_id": "123",
      "subject": "Model Performance Update",
      "url": "https://your-server/issues/123"
    }
  ],
  "question": "What is the latest model performance?"
}
\`\`\`

### \`GET /health\`
Health check endpoint

### \`POST /reset\`
Reset conversation history

### \`GET /users\`
List all users with conversation history

### \`DELETE /users/<user_name>\`
Delete user and their conversation history

## ğŸ”§ Configuration

### Environment Variables

| Variable | Description | Default |
|----------|-------------|---------|
| \`GEMINI_API_KEY\` | Google Gemini API key | (required) |
| \`VECTORDB_PATH\` | Path to ChromaDB database | \`/vectordb/chroma_db_v0.2.0\` |
| \`COLLECTION_NAME\` | ChromaDB collection name | \`your_collection_name\` |
| \`EMBEDDING_MODEL\` | Embedding model type | \`gemini\` |
| \`PORT\` | Server port | \`<PORT>\` |
| \`GUNICORN_WORKERS\` | Number of worker processes | \`6\` |
| \`LOG_LEVEL\` | Logging level | \`info\` |

For multiple data sources, add additional configuration with prefix (e.g., \`CRF_VECTORDB_PATH\`).

## ğŸ¯ Use Cases

### 1. Technical Documentation Search
Query project documentation, experiment results, and technical specifications.

### 2. Research Data Analysis
Analyze structured research data with automatic statistical calculations and visualization.

### 3. Multi-domain Knowledge Base
Integrate multiple knowledge bases with automatic query routing.

### 4. Conversational AI Assistant
Intelligent assistant that remembers context and handles follow-up questions.

## ğŸ”’ Security

- Store API keys in environment variables
- Use \`.env\` files for local development
- Implement authentication for production
- Use secret management systems (Kubernetes Secrets, AWS Secrets Manager)
- Regular security updates

## ğŸ“Š Performance

- **Response Time**: < 3 seconds for typical queries
- **Concurrent Users**: Scales with Gunicorn workers
- **Vector Search**: Optimized with ChromaDB HNSW indexing

## ğŸš¢ Deployment

### Docker Deployment

\`\`\`bash
# Build image
docker build -t rag-chatbot:latest ./chatbot

# Run container
docker run -d -p <PORT>:<PORT> -v ./vectordb:/vectordb -e GEMINI_API_KEY=your_key --name rag-chatbot rag-chatbot:latest
\`\`\`

### Kubernetes

Kubernetes manifests included for production deployment.

## ğŸ“ˆ Roadmap

- [ ] Support for more LLM providers
- [ ] Advanced analytics dashboard
- [ ] Multi-language support
- [ ] Voice input/output capabilities
- [ ] Additional data source integrations

## ğŸ“ License

MIT License

## ğŸ‘¨â€ğŸ’» Contributing

Contributions are welcome! Please feel free to submit issues and pull requests.
