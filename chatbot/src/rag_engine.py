"""Redmine RAG Engine - ChromaDB + Gemini (ë¦¬íŒ©í† ë§ ë²„ì „)"""
import logging
import os
import chromadb
from google import genai
from sentence_transformers import SentenceTransformer
from utils.rag_utils import RAGHelperMixin
from utils.crf_statistics import CRFStatisticsMixin
from utils.rag_engine_helpers import QueryHelperMixin
from config import constants as C


logger = logging.getLogger(__name__)

class RedmineRAG(RAGHelperMixin, CRFStatisticsMixin, QueryHelperMixin):
    def __init__(self, vectordb_path: str, collection_name: str, gemini_api_key: str,
                 embedding_model: str = "sentence-transformers", redmine_url: str = None,
                 use_case: str = "redmine", conversation_db_path: str = None,
                 crf_collection_name: str = None):
        logger.info(f"ğŸ”§ RAG ì—”ì§„ ì´ˆê¸°í™”: {collection_name} ({embedding_model})")

        self.redmine_url = redmine_url or "https://redmine.<INTERNAL-IP>.nip.io:30443"
        self.embedding_type = embedding_model
        self.use_case = use_case

        # ë©”ì¸ DB í´ë¼ì´ì–¸íŠ¸
        self.client = chromadb.PersistentClient(path=vectordb_path)

        # use_caseë³„ ì»¬ë ‰ì…˜ ë¶„ë¦¬
        if use_case == "crf":
            crf_col = crf_collection_name or "crf_all_cancers_v0_3_1"
            self.collection = self.client.get_collection(name=crf_col)
            logger.info(f"  - CRF ì»¬ë ‰ì…˜: {crf_col}")
        else:
            self.collection = self.client.get_collection(name=collection_name)
            logger.info(f"  - ë©”ì¸ ì»¬ë ‰ì…˜: {collection_name}")

        # ëŒ€í™” ì´ë ¥ DB (ë³„ë„ ê²½ë¡œ)
        try:
            conversation_path = conversation_db_path or os.path.join(os.path.dirname(vectordb_path), "conversation_db")
            self.conversation_client = chromadb.PersistentClient(path=conversation_path)
            self.conversation_collection = self.conversation_client.get_or_create_collection(
                name="conversation_history",
                metadata={"description": "Multi-turn conversation history"}
            )
            logger.info(f"  - ëŒ€í™” ì´ë ¥ DB: {conversation_path}")
            logger.info(f"  - ëŒ€í™” ì´ë ¥: {self.conversation_collection.count()}ê°œ")
        except Exception as e:
            logger.warning(f"  âš ï¸ ëŒ€í™” ì´ë ¥ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.conversation_collection = None

        # Gemini Client ìƒì„±
        self.genai_client = genai.Client(api_key=gemini_api_key)
        # Code Execution/ì°¨íŠ¸ìš©: ìµœì‹  Flash (ë¹ ë¥´ê³  ì•ˆì •ì )
        self.model_name = 'gemini-3-flash-preview'
        # Q&Aìš©: ì•ˆì •ì ì¸ 2.5-pro
        self.model_name_pro = 'gemini-2.5-pro'

        logger.info(f"âœ… Gemini Client ì´ˆê¸°í™” ì™„ë£Œ (ëª¨ë¸: {self.model_name_pro})")

        if embedding_model == "gemini":
            # gemini-embedding-001: ì•ˆì • ë²„ì „ (ê¶Œì¥)
            self.embedding_model_name = "models/gemini-embedding-001"
        else:
            self.embedding_model = SentenceTransformer('intfloat/multilingual-e5-large')

        logger.info("âœ… RAG ì—”ì§„ ì¤€ë¹„ ì™„ë£Œ!")

    def query(self, question: str, top_k: int = None, chat_history: list = None, session_id: str = None) -> dict:
        """
        ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ìƒì„± (Multi-turn ì§€ì› + ê³¼ê±° ëŒ€í™” ê²€ìƒ‰)
        ë¦¬íŒ©í† ë§: í—¬í¼ ë©”ì„œë“œ í™œìš©ìœ¼ë¡œ ê°„ê²°í™” (532ì¤„ â†’ 60ì¤„)
        """
        try:
            if chat_history is None:
                chat_history = []

            recent_query = self._is_recent_query(question)

            # 1. íŠ¹ìˆ˜ ì§ˆë¬¸ íƒ€ì… ì²˜ë¦¬ (early return)
            if self._is_general_conversation(question):
                return self._handle_general_conversation(question)

            if self._is_conversation_history_query(question):
                return self._handle_conversation_history_query(question, session_id)

            # 2. CRF ë©”íƒ€ë°ì´í„° ì§ˆë¬¸ (ì´ˆê¸° ì²´í¬)
            if self.use_case == "crf" and self._is_metadata_query(question):
                hospital_code = self._extract_hospital_code_from_question(question)
                return self._handle_crf_metadata_query(question, hospital_code, chat_history)

            # 3. CRF í†µê³„/ì°¨íŠ¸ ì§ˆë¬¸ì€ ë°”ë¡œ ì²˜ë¦¬ (ë²¡í„° ê²€ìƒ‰ ìƒëµ)
            if self.use_case == "crf" and self._is_statistics_query(question):
                hospital_code = self._extract_hospital_code_from_question(question)
                return self._handle_crf_statistics_query(question, hospital_code)

            # 4. ì§ì ‘ ì¡°íšŒ ì‹œë„ (ì´ìŠˆ ë²ˆí˜¸ ë˜ëŠ” CRF record_id)
            direct_results = self._perform_direct_lookup(question)

            # 5. ê³¼ê±° ëŒ€í™” ê²€ìƒ‰
            relevant_history = []
            if session_id and len(chat_history) >= C.CHAT_HISTORY_CONFIG['search_history_threshold']:
                relevant_history = self.search_conversation_history(
                    session_id, question, 
                    top_k=C.CHAT_HISTORY_CONFIG['max_relevant_history']
                )
                if relevant_history:
                    logger.info(f"  ğŸ“š ê´€ë ¨ ê³¼ê±° ëŒ€í™”: {len(relevant_history)}ê°œ ë°œê²¬")

            # 6. Top-K ê²°ì •
            top_k = self._determine_top_k(question, top_k, recent_query)

            # 7. ë¬¸ì„œ ê²€ìƒ‰
            documents, metadatas, distances = self._search_documents(
                question, chat_history, direct_results, top_k
            )

            if not documents:
                return {
                    "answer": "ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                    "sources": [],
                    "question": question
                }

            # 8. ë¬¸ì„œ í›„ì²˜ë¦¬ (ë²„ì „ ì¬ì •ë ¬, ìµœì‹ ìˆœ ì •ë ¬, í‚¤ì›Œë“œ ë³´ê°•)
            documents, metadatas, distances = self._post_process_documents(
                documents, metadatas, distances, question, recent_query
            )

            # 9. ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± ë° ë‹µë³€ ìƒì„±
            return self._generate_answer(
                question, documents, metadatas, distances, 
                chat_history, relevant_history
            )

        except Exception as e:
            logger.error(f"âŒ ì¿¼ë¦¬ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            raise

    def compare_collection_similarity(self, question: str) -> dict:
        """ì»¬ë ‰ì…˜ ìœ ì‚¬ë„ ë¹„êµ (ë¼ìš°íŒ…ìš©)"""
        try:
            query_embedding = self._embed(question, "RETRIEVAL_QUERY")
            results = self.collection.query(
                query_embeddings=[query_embedding],
                n_results=1
            )
            distances = results.get('distances', [[]])[0]
            current_distance = distances[0] if distances else float('inf')
            return {
                'distance': current_distance,
                'collection_name': self.collection.name
            }
        except Exception as e:
            logger.error(f"âŒ ìœ ì‚¬ë„ ë¹„êµ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return {
                'distance': float('inf'),
                'collection_name': self.collection.name
            }
